{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"model-for-colab.ipynb","provenance":[],"collapsed_sections":["LZmoX2X5F8dL","li0XceWNGeyj","H898KG3cG6z2","dvICAQLjHMLb","ycQtIRDvHbAF","XICDIuXxHpnC"],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"LZmoX2X5F8dL","colab_type":"text"},"source":["# Import, mount Google Drive, make ready the dataset"]},{"cell_type":"code","metadata":{"id":"9ZD_ZFaQF99u","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","from __future__ import print_function \n","from __future__ import division\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import torchvision\n","from torch.autograd import Variable\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","import csv\n","import pandas as pd\n","print(\"PyTorch Version: \",torch.__version__)\n","print(\"Torchvision Version: \",torchvision.__version__)\n","!pwd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7kska-0F_n7","colab_type":"code","colab":{}},"source":["#mount Google Drive to Colab\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-_eQNIkGAqE","colab_type":"code","colab":{}},"source":["#this part unzips the dataset in google colab\n","import zipfile\n","nih_data_path = \"drive/My Drive/NIH Dataset Small/\"\n","filename = \"NIH small.zip\"\n","with zipfile.ZipFile(nih_data_path + filename, 'r') as zip_ref:\n","    zip_ref.extractall()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9c0u_GDrGAsr","colab_type":"code","colab":{}},"source":["#check if all the images have been unzipped\n","files_list = os.listdir('NIH small')\n","print(len(files_list))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ryHk_lDGAvU","colab_type":"code","colab":{}},"source":["#test if loading images works\n","from PIL import Image\n","# data_dir = 'images'\n","# data_dir = '/content/images'\n","data_dir = 'NIH small'\n","# /content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive\n","# 00000001_000.png\n","# os.chdir('/content')\n","image = Image.open(data_dir + '/00000001_000.png')\n","# plt.imshow(np.asarray(image))\n","from IPython.display import display\n","display(image)\n","print(image.size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DrQdV9sVGMjN","colab_type":"text"},"source":["Define some main parameters needed later"]},{"cell_type":"code","metadata":{"id":"eF9TmXo6GA0B","colab_type":"code","colab":{}},"source":["data_dir = 'NIH small'\n","repo_directory = '/content/drive/My Drive/colab-repo'\n","\n","# Number of classes in the dataset\n","num_classes = 14\n","\n","batch_size = 16\n","WEIGHT_DECAY = 0\n","LR = 0.01\n","feature_extract = False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"li0XceWNGeyj","colab_type":"text"},"source":["# Create training function, checkpoint functions and define the models"]},{"cell_type":"code","metadata":{"id":"ZFkQXdt_GjrZ","colab_type":"code","colab":{}},"source":["def checkpoint(model, best_loss, epoch, LR):\n","    \"\"\"\n","    Saves checkpoint of torchvision model during training.\n","\n","    Args:\n","        model: torchvision model to be saved\n","        best_loss: best val loss achieved so far in training\n","        epoch: current epoch of training\n","        LR: current learning rate in training\n","    Returns:\n","        None\n","    \"\"\"\n","    # os.chdir('/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive')\n","    print('saving')\n","    state = {\n","        'model': model,\n","        'best_loss': best_loss,\n","        'epoch': epoch,\n","        'rng_state': torch.get_rng_state(),\n","        'LR': LR\n","    }\n","\n","    torch.save(state, repo_directory + '/results/checkpoint')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8uK4t0yYGlSe","colab_type":"code","colab":{}},"source":["\"\"\"\n","    Saves checkpoint of torchvision model during training.\n","\n","    Args:\n","        model: torchvision model, whose states needs to be saved\n","        best_loss: best val loss achieved so far in training\n","        epoch: current epoch of training\n","        LR: current learning rate in training\n","    Returns:\n","        None\n","    \"\"\"\n","def checkpoint_state(model, best_loss, epoch, LR):\n","  state = {\n","      'model_state': model.state_dict()\n","  }\n","  print('saving model state')\n","  torch.save(state, repo_directory + '/results/checkpoint-state')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PXU462YgGlUu","colab_type":"code","colab":{}},"source":["#function to calculate the positive and negative samples in a batch. It returns the coefficient to use for weighting\n","def pos_neg_weights_in_batch(labels_batch):\n","    num_total = labels_batch.shape[0] * labels_batch.shape[1]\n","    num_positives = labels_batch.sum()\n","    num_negatives = num_total - num_positives\n","\n","    if not num_positives == 0:\n","        beta_p = num_negatives / num_positives\n","    else:\n","        beta_p = num_negatives\n","    # beta_p = torch.tensor(beta_p)\n","    beta_p = beta_p.to(device)\n","    beta_p = beta_p.type(torch.cuda.FloatTensor)\n","\n","    return beta_p\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uh3jIcPJGlXI","colab_type":"code","colab":{}},"source":["def train_model(\n","        model,\n","        criterion,\n","        optimizer,\n","        LR,\n","        num_epochs,\n","        dataloaders,\n","        dataset_sizes,\n","        weight_decay, stop=True, decay = True, print_time = 1000):\n","    \"\"\"\n","    Fine tunes torchvision model to NIH CXR data.\n","\n","    Args:\n","        model: torchvision model to be finetuned (densenet-121 in this case)\n","        criterion: loss criterion (binary cross entropy loss, BCELoss)\n","        optimizer: optimizer to use in training (SGD)\n","        LR: learning rate\n","        num_epochs: continue training up to this many epochs\n","        dataloaders: pytorch train and val dataloaders\n","        dataset_sizes: length of train and val datasets\n","        weight_decay: weight decay parameter we use in SGD with momentum\n","    Returns:\n","        model: trained torchvision model\n","        best_epoch: epoch on which best model val loss was obtained\n","\n","    \"\"\"\n","    print('Hyperparameters: ')\n","    print('Learning rate:', LR)\n","    print('Weight decay:', weight_decay)\n","    print('Decaying:', decay)\n","    print('Num of epochs:', num_epochs)\n","    print(optimizer)\n","    since = time.time()\n","    stats = {'val_loss_history': [], 'train_loss_history': []}\n","    start_epoch = 1\n","    best_loss = 999999\n","    best_epoch = -1\n","    best_loss_train = 999999\n","    best_epoch_training = -1\n","    last_train_loss = -1\n","\n","    # iterate over epochs\n","    for epoch in range(start_epoch, num_epochs + 1):\n","        print('Epoch {}/{}'.format(epoch, num_epochs))\n","        print('-' * 10)\n","\n","        # set model to train or eval mode based on whether we are in train or\n","        # val; necessary to get correct predictions given batchnorm\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train(True)\n","            else:\n","                model.train(False)\n","\n","            running_loss = 0.0\n","            # running_loss2 = 0.0\n","\n","            i = 0\n","            total_done = 0\n","            # iterate over all data in train/val dataloader:\n","            for idx, data in enumerate(dataloaders[phase]):\n","                i += 1\n","                inputs, labels, _ = data\n","                batch_size = inputs.shape[0]\n","                inputs = Variable(inputs.to(device))\n","                labels = Variable(labels.float().to(device))\n","                outputs = model(inputs)\n","\n","                # calculate gradient and update parameters in train phase\n","                optimizer.zero_grad()\n","\n","\n","                #This is weighting in the batches both, the positive and negative samples\n","                # P = 0\n","                # N = 0        \n","                # for idxi, label in enumerate(labels):\n","                #     for v in label:\n","                #         if int(v) == 1:\n","                #             P = P + 1\n","                #         else:\n","                #             N = N + 1\n","                # if P!=0 and N!=0:\n","                #     BP = (P + N)/P\n","                #     BN = (P + N)/N\n","                #     weights = torch.tensor([BP, BN], dtype=torch.float).to(device)\n","                #     # print(BP, BN)\n","                # else: weights = None\n","                # # print('beta mine', N/P)\n","\n","\n","                beta = pos_neg_weights_in_batch(labels)\n","                criterion = nn.BCEWithLogitsLoss(pos_weight=beta)\n","                loss  = criterion(outputs, labels)\n","                # loss = weighted_BCELoss(outputs, labels, weights=weights)\n","                if phase == 'train':\n","                    loss.backward()\n","                    optimizer.step()\n","                running_loss += loss.item() * batch_size\n","\n","\n","                if((idx+1) % print_time == 0):\n","                    print(\"Loss of iteration {} is: {}\".format(idx + 1, loss.item() * batch_size))\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            if phase == 'train':\n","                last_train_loss = epoch_loss\n","                stats['train_loss_history'].append(epoch_loss)\n","            if phase == 'val':\n","                stats['val_loss_history'].append(epoch_loss)\n","\n","            print(phase + ' epoch {}:loss {:.4f} with data size {}'.format(\n","                epoch, epoch_loss, dataset_sizes[phase]))\n","            \n","            # decay learning rate if no val loss improvement in this epoch\n","            if phase == 'val' and epoch_loss > best_loss and decay:\n","                print(\"decay loss from \" + str(LR) + \" to \" +\n","                      str(LR / 10) + \" as not seeing improvement in val loss\")\n","                LR = LR / 10\n","                print('The new learning rate is: ', LR)\n","                # create new optimizer with lower learning rate\n","                # optimizer = optim.SGD(\n","                #     filter(\n","                #         lambda p: p.requires_grad,\n","                #         model.parameters()),\n","                #     lr=LR,\n","                #     momentum=0.9,\n","                #     weight_decay=weight_decay)\n","                optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model_ft.parameters()), lr = LR, betas = (0.9, 0.999))\n","                print(\"created new optimizer with LR \" + str(LR))\n","\n","            # checkpoint model if it has the best val loss yet\n","            if phase == 'train' and epoch_loss < best_loss_train:\n","                best_loss_train = epoch_loss\n","                best_epoch_train = epoch\n","\n","            # checkpoint model if it has the best train loss yet\n","            if phase == 'val' and epoch_loss < best_loss:\n","                best_loss = epoch_loss\n","                best_epoch = epoch\n","                checkpoint(model, best_loss, epoch, LR)\n","                checkpoint_state(model, best_loss, epoch, LR)\n","\n","            # log training and validation loss over each epoch\n","            if phase == 'val':\n","                with open(repo_directory + \"/results/log_train\", 'a') as logfile:\n","                    logwriter = csv.writer(logfile, delimiter=',')\n","                    if(epoch == 1):\n","                        logwriter.writerow([\"epoch\", \"train_loss\", \"val_loss\"])\n","                    logwriter.writerow([epoch, last_train_loss, epoch_loss])\n","\n","        total_done += batch_size\n","        if(total_done % (100 * batch_size) == 0):\n","            print(\"completed \" + str(total_done) + \" so far in epoch\")\n","\n","        # break if no val loss improvement in 3 epochs\n","        if ((epoch - best_epoch) >= 3) and stop:\n","            print(\"no improvement in 3 epochs, break\")\n","            break\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","\n","#     load best model weights to return\n","    checkpoint_best = torch.load(repo_directory + '/results/checkpoint')\n","    model = checkpoint_best['model']\n","\n","    return model, best_epoch, best_epoch_train, stats, LR"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U9MzLccKGlZV","colab_type":"code","colab":{}},"source":["def visualize_loss(stats):\n","    plt.subplot(2, 1, 2)\n","    plt.plot(stats['train_loss_history'], label='train')\n","    plt.plot(stats['val_loss_history'], label='val')\n","    plt.title('Train and validation loss history')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3u1m4e2Rgk4C","colab_type":"text"},"source":["Set Model Parametersâ€™ .requires_grad attribute\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","\n","This helper function sets the ``.requires_grad`` attribute of the\n","parameters in the model to False when we are feature extracting. By\n","default, when we load a pretrained model all of the parameters have\n","``.requires_grad=True``, which is fine if we are training from scratch\n","or finetuning. However, if we are feature extracting and only want to\n","compute gradients for the newly initialized layer then we want all of\n","the other parameters to not require gradients. \n","\n"]},{"cell_type":"code","metadata":{"id":"qEHa4zzmGlem","colab_type":"code","colab":{}},"source":["def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3WY6RAgzA2oL","colab_type":"text"},"source":["**This is the definition of the encoder model for Tiramisu**"]},{"cell_type":"code","metadata":{"id":"vR_L_L98GzUM","colab_type":"code","colab":{}},"source":["os.chdir(repo_directory)\n","from tiramisu.transition_down import TransitionDown\n","from tiramisu.dense_block import DenseBlock\n","\n","from torch.nn import Module, Conv2d, BatchNorm2d, Linear, init\n","from torch.nn import Sequential\n","from typing import Optional, Sequence, Union\n","\n","class FCDenseNet(Module):\n","    def __init__(self,\n","                 in_channels: int = 3,\n","                 out_channels: int = 1,\n","                 initial_num_features: int = 48,\n","                 dropout: float = 0.2,\n","\n","                 down_dense_growth_rates: Union[int, Sequence[int]] = 16,\n","                 down_dense_bottleneck_ratios: Union[Optional[int], Sequence[Optional[int]]] = None,\n","                 down_dense_num_layers: Union[int, Sequence[int]] = (4, 5, 7, 10, 12),\n","                 down_transition_compression_factors: Union[float, Sequence[float]] = 1.0,\n","\n","                 middle_dense_growth_rate: int = 16,\n","                 middle_dense_bottleneck: Optional[int] = None,\n","                 middle_dense_num_layers: int = 15,\n","\n","                 up_dense_growth_rates: Union[int, Sequence[int]] = 16,\n","                 up_dense_bottleneck_ratios: Union[Optional[int], Sequence[Optional[int]]] = None,\n","                 up_dense_num_layers: Union[int, Sequence[int]] = (12, 10, 7, 5, 4)):\n","      \n","        super(FCDenseNet, self).__init__()\n","\n","        # region Parameters handling\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","\n","        if type(down_dense_growth_rates) == int:\n","            down_dense_growth_rates = (down_dense_growth_rates,) * 5\n","        if down_dense_bottleneck_ratios is None or type(down_dense_bottleneck_ratios) == int:\n","            down_dense_bottleneck_ratios = (down_dense_bottleneck_ratios,) * 5\n","        if type(down_dense_num_layers) == int:\n","            down_dense_num_layers = (down_dense_num_layers,) * 5\n","        if type(down_transition_compression_factors) == float:\n","            down_transition_compression_factors = (down_transition_compression_factors,) * 5\n","\n","        if type(up_dense_growth_rates) == int:\n","            up_dense_growth_rates = (up_dense_growth_rates,) * 5\n","        if up_dense_bottleneck_ratios is None or type(up_dense_bottleneck_ratios) == int:\n","            up_dense_bottleneck_ratios = (up_dense_bottleneck_ratios,) * 5\n","        if type(up_dense_num_layers) == int:\n","            up_dense_num_layers = (up_dense_num_layers,) * 5\n","        # endregion\n","\n","        # region First convolution\n","        self.features = Conv2d(in_channels, initial_num_features, kernel_size=3, padding=1, bias=False)\n","        current_channels = self.features.out_channels\n","        # endregion\n","\n","        # region Downward path\n","        # Pairs of Dense Blocks with input concatenation and TransitionDown layers\n","        down_dense_params = [\n","            {\n","                'concat_input': True,\n","                'growth_rate': gr,\n","                'num_layers': nl,\n","                'dense_layer_params': {\n","                    'dropout': dropout,\n","                    'bottleneck_ratio': br\n","                }\n","            }\n","            for gr, nl, br in\n","            zip(down_dense_growth_rates, down_dense_num_layers, down_dense_bottleneck_ratios)\n","        ]\n","\n","        down_transition_params = [\n","            {\n","                'dropout': dropout,\n","                'compression': c\n","            } for c in down_transition_compression_factors\n","        ]\n","\n","        # skip_connections_channels = []\n","\n","        self.down_dense = Module()\n","        self.down_trans = Module()\n","\n","        down_pairs_params = zip(down_dense_params, down_transition_params)\n","        for i, (dense_params, transition_params) in enumerate(down_pairs_params):\n","            block = DenseBlock(current_channels, **dense_params)\n","            current_channels = block.out_channels\n","            self.down_dense.add_module(f'block_{i}', block)\n","\n","            # skip_connections_channels.append(block.out_channels)\n","\n","            transition = TransitionDown(current_channels, **transition_params)\n","            current_channels = transition.out_channels\n","            self.down_trans.add_module(f'trans_{i}', transition)\n","        # endregion\n","\n","        # region Middle block\n","        # Renamed from \"bottleneck\" in the paper, to avoid confusion with the Bottleneck of DenseLayers\n","        self.middle = DenseBlock(\n","            current_channels,\n","            middle_dense_growth_rate,\n","            middle_dense_num_layers,\n","            concat_input=True,\n","            dense_layer_params={\n","                'dropout': dropout,\n","                'bottleneck_ratio': middle_dense_bottleneck\n","            })\n","        current_channels = self.middle.out_channels\n","        # endregion\n","        # print('current channels:', current_channels)\n","\n","        # Final batch norm\n","        # self.features.add_module('norm5', nn.BatchNorm2d(current_channels)\n","        self.final_batch_norm = nn.BatchNorm2d(current_channels)\n","        \n","        # Linear layer\n","        self.classifier = nn.Linear(current_channels, self.out_channels)\n","\n","        # region Weight initialization\n","        for module in self.modules():\n","            if isinstance(module, Conv2d):\n","                init.kaiming_normal_(module.weight)\n","            elif isinstance(module, BatchNorm2d):\n","                module.reset_parameters()\n","            elif isinstance(module, Linear):\n","                init.xavier_uniform_(module.weight)\n","                init.constant_(module.bias, 0)\n","        # endregion\n","\n","    def forward(self, x):\n","        res = self.features(x)\n","\n","        skip_tensors = []\n","        for dense, trans in zip(self.down_dense.children(), self.down_trans.children()):\n","            res = dense(res)\n","            skip_tensors.append(res)\n","            res = trans(res)\n","\n","        res = self.middle(res)\n","        res = self.final_batch_norm(res)\n","        res = torch.nn.functional.relu(res, inplace=True)\n","        res = torch.nn.functional.adaptive_avg_pool2d(res, (1, 1))\n","        res = torch.flatten(res, 1)\n","        res = self.classifier(res)\n","        return res"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8nML3c43GzWs","colab_type":"code","colab":{}},"source":["# model to use\n","class FCDenseNet103(FCDenseNet):\n","    def __init__(self, in_channels=3, out_channels=1000, dropout=0.0):\n","        super(FCDenseNet103, self).__init__(\n","            in_channels=in_channels,\n","            out_channels=out_channels,\n","            initial_num_features=48,\n","            dropout=dropout,\n","\n","            down_dense_growth_rates=16,\n","            down_dense_bottleneck_ratios=None,\n","            down_dense_num_layers=(4, 5, 7, 10, 12),\n","            down_transition_compression_factors=1.0,\n","\n","            middle_dense_growth_rate=16,\n","            middle_dense_bottleneck=None,\n","            middle_dense_num_layers=15,\n","\n","            up_dense_growth_rates=16,\n","            up_dense_bottleneck_ratios=None,\n","            up_dense_num_layers=(12, 10, 7, 5, 4)\n","        )\n","os.chdir('/content')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xy75arK5GzZB","colab_type":"code","colab":{}},"source":["#Use this when you want to train the tiramisu encoder\n","model_ft = FCDenseNet103(in_channels=3,\n","                      out_channels=14,\n","                      dropout=0.2)\n","print(model_ft)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7s19mbJsGzfJ","colab_type":"code","colab":{}},"source":["#Use this method when you want to train the full densenet\n","def initialize_model(num_classes, feature_extract, use_pretrained=True):\n","    # Initialize these variables which will be set in this if statement. Each of these\n","    #   variables is model specific.\n","    model_ft = None\n","    input_size = 0\n","\n","    \"\"\" Densenet\n","        \"\"\"\n","    model_ft = models.densenet121(pretrained=use_pretrained)\n","    set_parameter_requires_grad(model_ft, feature_extract)\n","    num_ftrs = model_ft.classifier.in_features\n","    print('num_ftrs', num_ftrs)\n","    model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n","    # model_ft.classifier = nn.Sequential(nn.Linear(num_ftrs, num_classes), nn.Sigmoid())\n","    # model_ft.classifier = nn.Sequential(nn.Linear(num_ftrs, num_classes))\n","    input_size = 224\n","\n","    # model_ft.features.denseblock4 = nn.Sequential()\n","    # model_ft.features.transition3 = nn.Sequential()\n","\n","    # model_ft.features.transition2 = nn.Sequential()\n","    # model_ft.features.denseblock3 = nn.Sequential()\n","\n","    # model_ft.features.norm5 = nn.BatchNorm2d(512)\n","    # model_ft.classifier = nn.Linear(512, num_classes)\n","\n","\n","    return model_ft, input_size\n","\n","# Initialize the model for this run\n","model_ft, input_size = initialize_model(num_classes, feature_extract, use_pretrained=True)\n","\n","# Print the model we just instantiated\n","print(model_ft)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H898KG3cG6z2","colab_type":"text"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"SfwjhxDxG9UY","colab_type":"code","colab":{}},"source":["os.chdir(repo_directory)\n","import cxr_dataset as CXR\n","# Data augmentation and normalization for training\n","# Just normalization for validation\n","mean = [0.485, 0.456, 0.406]\n","std = [0.229, 0.224, 0.225]\n","    \n","data_transforms = {\n","        'train': transforms.Compose([\n","            # transforms.RandomHorizontalFlip(),\n","            # transforms.Resize(224),\n","            # because scale doesn't always give 224 x 224, this ensures 224 x\n","            # 224\n","            # transforms.CenterCrop(224),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean, std)\n","        ]),\n","        'val': transforms.Compose([\n","            # transforms.Resize(224),\n","            # transforms.CenterCrop(224),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean, std)\n","        ]),\n","    }\n","\n","print(\"Initializing Datasets and Dataloaders...\")\n","\n","# Create training and validation datasets\n","image_datasets = {}\n","image_datasets['train'] = CXR.CXRDataset(\n","    path_to_images=data_dir,\n","    fold='train',\n","    # sample = 10,\n","    transform=data_transforms['train'])\n","image_datasets['val'] = CXR.CXRDataset(\n","    path_to_images=data_dir,\n","    fold='val',\n","    # sample = 10,\n","    transform=data_transforms['val'])\n","# image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n","\n","# Create training and validation dataloaders\n","dataloaders_dict = {}\n","dataloaders_dict['train'] = torch.utils.data.DataLoader(\n","    image_datasets['train'],\n","    batch_size=batch_size,\n","    shuffle=True,\n","    num_workers=8)\n","dataloaders_dict['val'] = torch.utils.data.DataLoader(\n","    image_datasets['val'],\n","    batch_size=batch_size,\n","    shuffle=True,\n","    num_workers=8)\n","# dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","os.chdir('/content')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y81YMo5XG-YV","colab_type":"code","colab":{}},"source":["#Check dataset size\n","print(dataset_sizes)\n","image_datasets['val'].df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DxHosaUCG-j0","colab_type":"code","colab":{}},"source":["#check number of parameters\n","num_parameter_to_learn = 0\n","for name,param in model_ft.named_parameters():\n","  if param.requires_grad == True:\n","    num_parameter_to_learn = num_parameter_to_learn + 1\n","    print(\"\\t\",name)\n","print('Number of parameters: ' + str(num_parameter_to_learn))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dvICAQLjHMLb","colab_type":"text"},"source":["# Create the Optimizer"]},{"cell_type":"code","metadata":{"id":"GZr2j_t5HOj5","colab_type":"code","colab":{}},"source":["# Send the model to GPU\n","model_ft = model_ft.to(device)\n","\n","# Gather the parameters to be optimized/updated in this run. If we are\n","#  finetuning we will be updating all parameters. However, if we are \n","#  doing feature extract method, we will only update the parameters\n","#  that we have just initialized, i.e. the parameters with requires_grad\n","#  is True.\n","params_to_update = model_ft.parameters()\n","print(\"Params to learn:\")\n","if feature_extract:\n","    params_to_update = []\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update.append(param)\n","            # print(\"\\t\",name)\n","            \n","#just print the number of parameters\n","else:\n","    num_parameter_to_learn = 0\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            num_parameter_to_learn = num_parameter_to_learn + 1\n","            # print(\"\\t\",name)\n","    print('Number of parameters: ' + str(num_parameter_to_learn))\n","# Observe that all parameters are being optimized\n","# optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n","\n","# optimizer_ft = optim.SGD(\n","#         filter(lambda p: p.requires_grad, model_ft.parameters()),\n","#         lr=LR,\n","#         momentum=0.9,\n","#         weight_decay=WEIGHT_DECAY)\n","optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model_ft.parameters()), lr = LR, betas = (0.9, 0.999))\n","# optimizer_ft = optim.SGD(model_ft.parameters(), lr=LR, weight_decay=WEIGHT_DECAY, momentum=0.9)\n","print(optimizer_ft)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8mgLoV_RHW0o","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"ycQtIRDvHbAF","colab_type":"text"},"source":["# Do the training"]},{"cell_type":"code","metadata":{"id":"HNMoyS4_HjNn","colab_type":"code","colab":{}},"source":["def weighted_BCELoss(output, target, weights=None):\n","    output = output.clamp(min=1e-5, max=1-1e-5)\n","    target = target.float()\n","    if weights is not None:\n","        assert len(weights) == 2\n","\n","        loss = -weights[0] * (target * torch.log(output)) - weights[1] * ((1 - target) * torch.log(1 - output))\n","    else:\n","        loss = -target * torch.log(output) - (1 - target) * torch.log(1 - output)\n","    return torch.sum(loss)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E4zuI-ehHjQH","colab_type":"code","colab":{}},"source":["# criterion = nn.BCELoss()\n","criterion = nn.BCEWithLogitsLoss()\n","# Train and evaluate\n","model_ft, best_epoch, best_epoch_train, stats, LR = train_model(model_ft, criterion, optimizer_ft, LR, num_epochs,  dataloaders_dict, dataset_sizes, WEIGHT_DECAY, decay=False, print_time=100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kF4m0U4RHuog","colab_type":"code","colab":{}},"source":["visualize_loss(stats)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XICDIuXxHpnC","colab_type":"text"},"source":["# Calcualte AUCs"]},{"cell_type":"code","metadata":{"id":"4KulsIn-Hr8o","colab_type":"code","colab":{}},"source":["mean = [0.485, 0.456, 0.406]\n","std = [0.229, 0.224, 0.225]\n","    \n","data_transforms = {\n","        'train': transforms.Compose([\n","            transforms.RandomHorizontalFlip(),\n","            # transforms.Resize(224),\n","            # because scale doesn't always give 224 x 224, this ensures 224 x\n","            # 224\n","            # transforms.CenterCrop(224),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean, std)\n","        ]),\n","        'val': transforms.Compose([\n","            # transforms.Resize(224),\n","            # transforms.CenterCrop(224),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean, std)\n","        ]),\n","    }"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X0XXjgVeHsEb","colab_type":"code","colab":{}},"source":["os.chdir(repo_directory)\n","import torch\n","import pandas as pd\n","import cxr_dataset as CXR\n","from torchvision import transforms, utils\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import sklearn\n","import sklearn.metrics as sklm\n","from torch.autograd import Variable\n","import numpy as np\n","\n","\n","def make_pred_multilabel(data_transforms, model, PATH_TO_IMAGES):\n","    \"\"\"\n","    Gives predictions for test fold and calculates AUCs using previously trained model\n","\n","    Args:\n","        data_transforms: torchvision transforms to preprocess raw images; same as validation transforms\n","        model: densenet-121 from torchvision previously fine tuned to training data\n","        PATH_TO_IMAGES: path at which NIH images can be found\n","    Returns:\n","        pred_df: dataframe containing individual predictions and ground truth for each test image\n","        auc_df: dataframe containing aggregate AUCs by train/test tuples\n","    \"\"\"\n","\n","    # calc preds in batches of 16\n","    BATCH_SIZE = 16\n","\n","    # set model to eval mode; required for proper predictions given use of batchnorm\n","    model.train(False)\n","\n","    # create dataloader\n","    dataset = CXR.CXRDataset(\n","        path_to_images=PATH_TO_IMAGES,\n","        fold=\"test\",\n","        # sample = 200,\n","        transform=data_transforms['val'])\n","    os.chdir('/content')\n","    dataloader = torch.utils.data.DataLoader(\n","        dataset, BATCH_SIZE, shuffle=False, num_workers=8)\n","    size = len(dataset)\n","    print(size)\n","    # print('datasetsize', dataset_sizes)\n","    print(dataset.df)\n","\n","    # create empty dfs\n","    pred_df = pd.DataFrame(columns=[\"Image Index\"])\n","    true_df = pd.DataFrame(columns=[\"Image Index\"])\n","\n","    #these lists will save values for the second way of calculating the scores\n","    outputList = []\n","    labelList = []\n","\n","    # iterate over dataloader\n","    for idx, data in enumerate(dataloader):\n","\n","        inputs, labels, _ = data\n","        inputs = Variable(inputs.to(device))\n","        labels = Variable(labels.float().to(device))\n","\n","        true_labels = labels.cpu().data.numpy()\n","        batch_size = true_labels.shape\n","        outputs = model(inputs)\n","        outputs = torch.sigmoid(outputs)\n","        probs = outputs.cpu().data.numpy()\n","\n","        for i in range(outputs.shape[0]):\n","            outputList.append(outputs[i].tolist())\n","            labelList.append(labels[i].tolist())\n","\n","        # get predictions and true values for each item in batch\n","        # here the dataframe 'true' and 'preds' are created by adding rows into them respectively\n","        for j in range(0, batch_size[0]):\n","            thisrow = {}\n","            truerow = {}\n","            thisrow[\"Image Index\"] = dataset.df.index[BATCH_SIZE * idx + j]\n","            truerow[\"Image Index\"] = dataset.df.index[BATCH_SIZE * idx + j]\n","\n","            # iterate over each entry in prediction vector; each corresponds to\n","            # individual label\n","            for k in range(len(dataset.PRED_LABEL)):\n","                thisrow[\"prob_\" + dataset.PRED_LABEL[k]] = probs[j, k]\n","                truerow[dataset.PRED_LABEL[k]] = true_labels[j, k]\n","                # print('---------------')\n","                # print(dataset.df.index[BATCH_SIZE * idx + j])\n","                # print(probs[j])\n","                # print(true_labels[j])\n","                # print('---------------')\n","            pred_df = pred_df.append(thisrow, ignore_index=True)\n","            true_df = true_df.append(truerow, ignore_index=True)\n","            # print(pred_df)\n","            # print(head(true_df))\n","        if(idx % 100 == 0):\n","            print(str(idx * BATCH_SIZE))\n","            \n","    #This is another way of calculating AUCs. It does the calculating step by step\n","    print('Scores - Method2 -----------------------')        \n","    epoch_auc_ave = sklm.roc_auc_score(np.array(labelList), np.array(outputList))\n","    epoch_auc = sklm.roc_auc_score(np.array(labelList), np.array(outputList), average=None)\n","    for i, c in enumerate(dataset.PRED_LABEL):\n","        fpr, tpr, _ = sklm.roc_curve(np.array(labelList)[:, i], np.array(outputList)[:, i])\n","        plt.plot(fpr, tpr, label=c)\n","        print('{}: {:.4f} '.format(c, epoch_auc[i]))\n","    print('Scores - Method2 -----------------------')\n","    \n","    \n","\n","    #here the auc scores are calculated and the 'auc' table is created    \n","    auc_df = pd.DataFrame(columns=[\"label\", \"auc\"])\n","\n","    # calc AUCs\n","    for column in true_df:\n","\n","        if column not in [\n","            'Atelectasis',\n","            'Cardiomegaly',\n","            'Effusion',\n","            'Infiltration',\n","            'Mass',\n","            'Nodule',\n","            'Pneumonia',\n","            'Pneumothorax',\n","            'Consolidation',\n","            'Edema',\n","            'Emphysema',\n","            'Fibrosis',\n","            'Pleural_Thickening',\n","                'Hernia']:\n","                    continue\n","        actual = true_df[column]\n","        pred = pred_df[\"prob_\" + column]\n","        thisrow = {}\n","        thisrow['label'] = column\n","        thisrow['auc'] = np.nan\n","        try:\n","            thisrow['auc'] = sklm.roc_auc_score(\n","                actual.values.astype(int), pred.values)\n","        except BaseException as e:\n","            print('-------------------')\n","            print(e)\n","            print(actual.values)\n","            print(pred.values)\n","            print('-------------------')\n","            \n","        auc_df = auc_df.append(thisrow, ignore_index=True)\n","\n","    pred_df.to_csv(repo_directory + \"/results/preds.csv\", index=False)\n","    auc_df.to_csv(repo_directory + \"/results/aucs.csv\", index=False)\n","    true_df.to_csv(repo_directory + \"/results/true.csv\", index = False)\n","    return pred_df, auc_df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DR-scHQQHzF3","colab_type":"code","colab":{}},"source":["checkpoint_best = torch.load(repo_directory + '/results/checkpoint')\n","model = checkpoint_best['model']\n","model.eval()\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","preds, aucs = make_pred_multilabel(data_transforms, model, data_dir)"],"execution_count":0,"outputs":[]}]}